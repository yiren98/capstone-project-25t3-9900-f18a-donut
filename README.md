# Corporate Culture Monitor

## Project Structure

```
capstone-project-25t3-9900-f18a-donut/
â”‚
â”œâ”€ crawler/                                       # Initial data collection (platform-specific adapters)
â”‚  â”œâ”€ reddit-crawler-master/ 
â”‚  â”‚  â”œâ”€ Rio_tinto_crawler.py                     # Reddit crawler script for collecting Rio Tinto-related posts
â”‚  â”‚  â”œâ”€ export_to_csv.py                         # Export Reddit SQLite data into CSV format
â”‚  â”‚  â”œâ”€ process_submissions.py                   # Process and normalize Reddit submission data
â”‚  â”‚  â””â”€ reddit_data.db                           # Local SQLite database storing raw Reddit data
â”‚  â”œâ”€ adapters/                                   # Data cleaning & field normalization
â”‚  â”‚  â”œâ”€ reddit_adapter.py                        # Adapter for Reddit data structure
â”‚  â”‚  â”œâ”€ twitter_adapter.py                       # Adapter for Twitter/X data structure
â”‚  â”‚  â””â”€ guardian_adapter.py                      # Adapter for The Guardian news articles
â”‚  â””â”€ aggregator.py                               # Multi-source data aggregation and unification
â”‚  
â”œâ”€ data/
â”‚  â”œâ”€ raw/                                        # Raw and cleaned data from each source
â”‚  â”‚  â”œâ”€ reddit/                                  # Reddit raw data files
â”‚  â”‚  â”œâ”€ twitter/                                 # Twitter raw data files
â”‚  â”‚  â””â”€ guardian/                                # The Guardian raw data files
â”‚  â”œâ”€ processed/
â”‚  â”‚  â”œâ”€ annotated.csv                            # Processed data with sentiment & dimension annotations
â”‚  â”‚  â””â”€ unified.csv                              # Unified CSV after aggregation (standardized schema)
â”‚  â””â”€ taxonomy/
â”‚     â”œâ”€ dimensions.txt                           # Preliminary list of cultural dimensions
â”‚     â””â”€ suggestions.csv                          # Dimension-based improvement suggestions
â”‚
backend/
â”‚
â”œâ”€â”€ dimensions_sr/                  # Dimension-level summary & recommendation JSONs
â”œâ”€â”€ subthemes_sr/                   # Subtheme-level summary & recommendation JSONs
â”œâ”€â”€ tests/                          # Pytest suite for backend pipeline
â”‚   â”œâ”€â”€ __init__.py                 # Mark tests/ as a Python package
â”‚   â”œâ”€â”€ test_data_process.py        # Tests for data_process.py
â”‚   â”œâ”€â”€ test_sentiment_dbcheck.py   # Tests for neutral re-check logic
â”‚   â”œâ”€â”€ test_mapping_sub2dim.py     # Tests for mapping_sub2dim.py
â”‚   â”œâ”€â”€ test_subtheme_classify_cluster.py  # Tests for subtheme clustering & dimension mapping
â”‚   â”œâ”€â”€ test_overall_sr.py          # Tests for overall_sr summary generator
â”‚   â”œâ”€â”€ test_subthe_dimen_sr.py     # Tests for subtheme/dimension summaries
â”‚   â”œâ”€â”€ test_pipeline_structure.py  # Sanity checks on pipeline wiring
â”‚   â”œâ”€â”€ test_suggestions.py         # Tests for suggestions utilities
â”‚   â”œâ”€â”€ test_imports.py             # Import coverage for backend modules
â”‚   â””â”€â”€ test_train_cr_encoder.py    # Tests for Cross-Encoder training helper
â”‚
â”œâ”€â”€ data_process.py                 # [Step 1] Generate comments.csv & subthemes.csv from raw data
â”œâ”€â”€ download_models.py              # [Step 1.5] Download required models, wrapped with a main entry
â”œâ”€â”€ sentiment_dbcheck.py            # [Step 2] Re-check neutral subthemes and refine sentiment
â”œâ”€â”€ train_cr_encoder.py             # [Step 3, optional] Train Cross-Encoder for subtheme â†’ dimension mapping
â”œâ”€â”€ subtheme_classify_cluster.py    # [Step 4] Predict dimensions & cluster subthemes, output dimension_clusters.json
â”œâ”€â”€ mapping_sub2dim.py              # [Step 5] Write representative subthemes & mapped dimensions back into comments.csv
â”œâ”€â”€ pipeline.py                     # One-command 5-step NLP workflow orchestrator
â”‚
â”œâ”€â”€ overall_sr.py                   # Generate an overall corporate culture summary JSON from comments.csv
â”œâ”€â”€ subthe_dimen_sr.py              # Generate JSON summaries for each subtheme & dimension (DeepSeek-based)
â”œâ”€â”€ suggestions.py                  # Utilities for suggestions & recommendation text generation
â”‚
â”œâ”€â”€ app.py                          # REST API server entrypoint
|
â”œâ”€â”€ overall_sr.json                 # Generated overall summary JSON (artefact)
â”œâ”€â”€ requirements.txt                # Python dependencies for backend
â”‚
â”œâ”€ frontend/                                      # React + Tailwind responsive web interface
â”‚  â”œâ”€ index.html                                  # Main HTML entry file (root mounting point for React)
â”‚  â”œâ”€ tailwind.config.js                          # Tailwind CSS configuration file
â”‚  â”œâ”€ Dockerfile/                                 # Frontend Docker image (Vite build + Nginx serve)
â”‚  â””â”€ src/
â”‚     â”œâ”€ App.jsx                                  # Main React app â€“ defines routes and global layout
â”‚     â”œâ”€ index.css                                # Global stylesheet (imports Tailwind and custom styles)
â”‚     â”œâ”€ main.jsx                                 # React entrypoint (mounts App to index.html)
â”‚     â”œâ”€ api.js                                   # API wrapper with Source parameter support
â”‚     â”œâ”€ components/                              # Reusable UI components
â”‚     â”‚  â”œâ”€ Header.jsx                            # Top navigation bar (logo, title, login/logout)
â”‚     â”‚  â”œâ”€ KpiCards.jsx                          # KPI summary cards (total, positive, negative, eNPS)
â”‚     â”‚  â”œâ”€ DateFilter.jsx                        # Date range filter for temporal filtering
â”‚     â”‚  â”œâ”€ RegionFilter.jsx                      # Region/location-based filter
â”‚     â”‚  â”œâ”€ DimensionFilter.jsx                   # Cultural dimension filter
â”‚     â”‚  â”œâ”€ SentimentTabs.jsx                     # Sentiment toggle tabs (positive/negative/all)
â”‚     â”‚  â”œâ”€ SourceFilter.jsx                      # Information source filter (Reddit / Guardian / Twitter)
â”‚     â”‚  â”œâ”€ DimensionSuggestions.jsx              # Dimension-specific recommendation display area
â”‚     â”‚  â”œâ”€ DetailView.jsx                        # Detail view or modal for full review/news content
â”‚     â”‚  â”œâ”€ LoginForm.jsx                         # Login form component (email/password input)
â”‚     â”‚  â””â”€ Pager.jsx                             # Pagination component for review lists
â”‚     â””â”€ routes/
â”‚        â””â”€ Login.jsx                             # Login page route (/login)
â”‚ 
â”œâ”€ deployment/                                    # Cloud deployment configuration (Docker Compose, CI/CD)
â”‚
â””â”€ README.md                                      # Project documentation and setup instructions
```

---

## Data Pipeline
```
[crawler/*] â†’ Collects multi-source data 
    â†’ saved in `data/raw/{reddit,twitter,guardian}/*.csv`
    â†“
[crawler/adapters/*] â†’ Cleans & normalizes fields 
    â†’ unified schema: ID, Location, Time, Text, Initial Dimensions, Source, Tag
    â†’ references taxonomy definitions in `data/taxonomy/dimensions.txt`
    â†“
[crawler/aggregator.py] â†’ Aggregates all sources 
    â†’ outputs `data/processed/unified.csv`
    â†“
[backend/pipeline.py]
    â†’ Runs the full 5-step NLP workflow:
      1. data_process.py
      2. sentiment_dbcheck.py
      3. train_cr_encoder.py (optional)
      4. subtheme_classify_cluster.py
      5. mapping_sub2dim.py
    â†’ Produces enriched `comments.csv` + `dimension_clusters.json`
    â†“
[backend/suggestions.py]
    â†’ Orchestrates all summary-generation modules:
        - Runs overall_sr.py to generate the overall summary JSON
        - Runs subthe_dimen_sr.py to generate per-subtheme & per-dimension summaries
    â†’ Stores JSON outputs into:
        - backend/overall_sr.json
        - backend/dimensions_sr/
        - backend/subthemes_sr/
    â†“
[backend/app.py] â†’ Serves RESTful APIs
    â†“
[frontend/src/api.js] â†’ Fetches API data (with Source, Time, Region, Sentiment filters)
    â†“
[frontend/src/App.jsx + components/*] â†’ Renders interactive dashboard in browser

```
---

## Setup & Run

### Backend

```bash
cd backend
python -m venv .venv
.venv\Scripts\activate      # (Windows)
# or
source .venv/bin/activate     # (Mac)
pip install -r requirements.txt
python app.py
```

### Frontend

```bash
cd frontend
npm install
npm run dev
```

ðŸ”— http://localhost:5173
