# Corporate Culture Monitor

## Project Structure

```
capstone-project-25t3-9900-f18a-donut/
â”‚
â”œâ”€ crawler/                                       # Initial data collection (platform-specific adapters)
â”‚  â”œâ”€ reddit-crawler-master/ 
â”‚  â”‚  â”œâ”€ Rio_tinto_crawler.py                     # Reddit crawler script for collecting Rio Tinto-related posts
â”‚  â”‚  â”œâ”€ export_to_csv.py                         # Export Reddit SQLite data into CSV format
â”‚  â”‚  â”œâ”€ process_submissions.py                   # Process and normalize Reddit submission data
â”‚  â”‚  â””â”€ reddit_data.db                           # Local SQLite database storing raw Reddit data
â”‚  â”œâ”€ adapters/                                   # Data cleaning & field normalization
â”‚  â”‚  â”œâ”€ reddit_adapter.py                        # Adapter for Reddit data structure
â”‚  â”‚  â”œâ”€ twitter_adapter.py                       # Adapter for Twitter/X data structure
â”‚  â”‚  â””â”€ guardian_adapter.py                      # Adapter for The Guardian news articles
â”‚  â””â”€ aggregator.py                               # Multi-source data aggregation and unification
â”‚  
â”œâ”€ data/
â”‚  â”œâ”€ raw/                                        # Raw and cleaned data from each source
â”‚  â”‚  â”œâ”€ reddit/                                  # Reddit raw data files
â”‚  â”‚  â”œâ”€ twitter/                                 # Twitter raw data files
â”‚  â”‚  â””â”€ guardian/                                # The Guardian raw data files
â”‚  â”œâ”€ processed/
â”‚  â”‚  â”œâ”€ annotated.csv                            # Processed data with sentiment & dimension annotations
â”‚  â”‚  â””â”€ unified.csv                              # Unified CSV after aggregation (standardized schema)
â”‚  â””â”€ taxonomy/
â”‚     â”œâ”€ dimensions.txt                           # Preliminary list of cultural dimensions
â”‚     â””â”€ suggestions.csv                          # Dimension-based improvement suggestions
â”‚
â”œâ”€ backend/                                       # Backend service layer (Flask API & model pipeline)
â”‚  â”œâ”€ app.py                                      # Flask API entrypoint (KPI endpoints, Tag validation & expansion)
â”‚  â”œâ”€ pipeline.py                                 # Sentiment & dimension classification pipeline
â”‚  â”œâ”€ download_models.py                          # Script for downloading or initializing NLP models
â”‚  â”œâ”€ suggestions.py                              # Automatic generation of dimension-level improvement suggestions
â”‚  â”œâ”€ Dockerfile/                                 # Backend Docker image definition
â”‚  â””â”€ tests.py                                    # Backend unit/integration tests
â”‚
â”œâ”€ frontend/                                      # React + Tailwind responsive web interface
â”‚  â”œâ”€ index.html                                  # Main HTML entry file (root mounting point for React)
â”‚  â”œâ”€ tailwind.config.js                          # Tailwind CSS configuration file
â”‚  â”œâ”€ Dockerfile/                                 # Frontend Docker image (Vite build + Nginx serve)
â”‚  â””â”€ src/
â”‚     â”œâ”€ App.jsx                                  # Main React app â€“ defines routes and global layout
â”‚     â”œâ”€ index.css                                # Global stylesheet (imports Tailwind and custom styles)
â”‚     â”œâ”€ main.jsx                                 # React entrypoint (mounts App to index.html)
â”‚     â”œâ”€ api.js                                   # API wrapper with Source parameter support
â”‚     â”œâ”€ components/                              # Reusable UI components
â”‚     â”‚  â”œâ”€ Header.jsx                            # Top navigation bar (logo, title, login/logout)
â”‚     â”‚  â”œâ”€ KpiCards.jsx                          # KPI summary cards (total, positive, negative, eNPS)
â”‚     â”‚  â”œâ”€ DateFilter.jsx                        # Date range filter for temporal filtering
â”‚     â”‚  â”œâ”€ RegionFilter.jsx                      # Region/location-based filter
â”‚     â”‚  â”œâ”€ DimensionFilter.jsx                   # Cultural dimension filter
â”‚     â”‚  â”œâ”€ SentimentTabs.jsx                     # Sentiment toggle tabs (positive/negative/all)
â”‚     â”‚  â”œâ”€ SourceFilter.jsx                      # Information source filter (Reddit / Guardian / Twitter)
â”‚     â”‚  â”œâ”€ DimensionSuggestions.jsx              # Dimension-specific recommendation display area
â”‚     â”‚  â”œâ”€ DetailView.jsx                        # Detail view or modal for full review/news content
â”‚     â”‚  â”œâ”€ LoginForm.jsx                         # Login form component (email/password input)
â”‚     â”‚  â””â”€ Pager.jsx                             # Pagination component for review lists
â”‚     â””â”€ routes/
â”‚        â””â”€ Login.jsx                             # Login page route (/login)
â”‚ 
â”œâ”€ deployment/                                    # Cloud deployment configuration (Docker Compose, CI/CD)
â”‚
â””â”€ README.md                                      # Project documentation and setup instructions
```

---

## Data Pipeline
```
[crawler/*] â†’ Collects multi-source data 
    â†’ saved in `data/raw/{reddit,twitter,guardian}/*.csv`
    â†“
[crawler/adapters/*] â†’ Cleans & normalizes fields 
    â†’ unified schema: ID, Location, Time, Text, Initial Dimensions, Source, Tag
    â†’ references taxonomy definitions in `data/taxonomy/dimensions.txt`
    â†“
[crawler/aggregator.py] â†’ Aggregates all sources 
    â†’ outputs `data/processed/unified.csv`
    â†“
[backend/pipeline.py] â†’ Performs sentiment & dimension analysis 
    â†’ outputs annotated results to `data/processed/annotated.csv`
    â†“
[backend/suggestions.py] â†’ Generates improvement suggestions by dimension 
    â†’ saves to `data/taxonomy/suggestions.csv`
    â†“
[backend/app.py] â†’ Serves RESTful APIs
    â†“
[frontend/src/api.js] â†’ Fetches API data (with Source, Time, Region, Sentiment filters)
    â†“
[frontend/src/App.jsx + components/*] â†’ Renders interactive dashboard in browser

```
---

## Setup & Run

### Backend

```bash
cd backend
python -m venv .venv
.venv\Scripts\activate      # (Windows)
# or
source .venv/bin/activate     # (Mac)
pip install -r requirements.txt
python app.py
```

### Frontend

```bash
cd frontend
npm install
npm run dev
```

ðŸ”— http://localhost:5173
